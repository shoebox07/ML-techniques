{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cc0adff",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af7290",
   "metadata": {},
   "source": [
    "Lasso Regression is a regularized regression technique that takes advantage of both sparsity and convexity. We choose a Beta that minimizes the following:\n",
    "\n",
    "β̂ = argmin(β) $\\frac{1}{2n}  \\sum \\limits _{i=1} ^{n} (Y_{i} - \\beta^T X_{i})^2 + \\lambda \\lvert\\lvert \\beta \\rvert\\rvert_{1}$\n",
    "\n",
    "We select $\\lambda$ by using leave-one-out cross-validation to measure the risk and choose the $\\lambda$ that gives us the smallest risk. Afterwards, we refit the model with the non-zero coefficients using linear regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9d8618",
   "metadata": {},
   "source": [
    "Load the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a564bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.linear_model import Lasso\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e913e0",
   "metadata": {},
   "source": [
    "Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8ca415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y = pd.read_pickle('') #Uncomment and put in the file location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807ac37",
   "metadata": {},
   "source": [
    "Standarize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e571c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = y - np.mean(y) #Standarize the variables\n",
    "Xs = (X - np.mean(X, axis=0))/ np.std(X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d930d",
   "metadata": {},
   "source": [
    "Plot a graph to see how the coefficients shrink at Lambda increases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c096548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0.01,1,10000) #Initalize the lassos\n",
    "lasso = Lasso() \n",
    "coefs = []\n",
    "\n",
    "for a in alphas: #Iterate through each alpha\n",
    "    lasso.set_params(alpha=a) #Set the lasso with the current alpha\n",
    "    lasso.fit(Xs, ys) #Fit the lasso\n",
    "    coefs.append(lasso.coef_) #Add coefs to coef\n",
    "\n",
    "plt.figure(figsize=(10,8))    \n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('Standardized Coefficients')\n",
    "plt.title('Lasso coefficients vs. regularization lambda');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e0c89a",
   "metadata": {},
   "source": [
    "Function that will store all of the risk values for each lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97717616",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0.001, 1, 1000) #this is an array of lambdas to test\n",
    "lasso = Lasso() #call lasso\n",
    "riskvector = []#store the risk for each lambda in here\n",
    "\n",
    "for a in alphas: #iterate through each lambda\n",
    "    lasso.set_params(alpha=a) #set the lambda for the lasso\n",
    "    lasso.fit(Xs,ys) #fit the model\n",
    "\n",
    "    S_hat = [] #create a list that will store the coefficents that aren't zero\n",
    "    for i in range(lasso.coef_.shape[0]): #iterate through each coefficient\n",
    "        if lasso.coef_[i] != -0.: #check to see if the coefficient isn't zero\n",
    "            S_hat.append(i) #append it to S_hat if it's not zero\n",
    "    S = len(S_hat) #create a new variable S and it will be equal to the length of S_hat\n",
    "    #S_hat has all of the non-zero coefficents so the length of it is the total number of non-zero coefs\n",
    "    \n",
    "    if S == 0: #if all coefficients are zero, break out of the for loop\n",
    "        break #Recall that as lambda goes to infity, the coefficients approach 0\n",
    "        #so we break out of the loop since from this alpha onwards the coefs will be zero\n",
    "    \n",
    "    selected_var = Xs[:, S_hat] #Subset of the variables whose coefficients aren't zero\n",
    "    \n",
    "    linear = LinearRegression() #call the linear regression function\n",
    "    linear.fit(selected_var, ys) #fit the model with the non-zero cofficients\n",
    "\n",
    "    ypre = linear.predict(selected_var) #predictions\n",
    "    \n",
    "    risk = ((1/n)*(np.sum((ys - ypre)**2)))/((1-(S/n))**2)\n",
    "    #calculate the risk using the formula on slide 15 on september 7th lecture\n",
    "    #this is basically a formula for leave-one-out cross-validation\n",
    "    \n",
    "    riskvector.append(risk) #add the risk to riskvector\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e59efc7",
   "metadata": {},
   "source": [
    "From here you can choose the lambda that gives you the lowest risk and refit the model with the non-zero coefficients using linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2bfe1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
